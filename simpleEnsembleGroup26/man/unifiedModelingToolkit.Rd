% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unifiedModelingToolkit_learner.R
\name{unifiedModelingToolkit}
\alias{unifiedModelingToolkit}
\title{Unified Modeling Toolkit for Machine Learning}
\usage{
unifiedModelingToolkit(
  X,
  y,
  models,
  bagging = FALSE,
  bagging_R = 100,
  ensemble = FALSE,
  feature_selection_method = NULL,
  k = NULL,
  drop_missing_records = TRUE,
  fill_missing_method = "mean",
  scale_data = FALSE,
  remove_outliers = FALSE,
  seed = 123,
  parameter_tuning = FALSE,
  cv_folds = 5,
  model_tuning_params = list(),
  classification_threshold = 0.5,
  ensemble_combine_method
)
}
\arguments{
\item{X}{Predictor variables as a dataframe or matrix.}

\item{y}{Response variable as a vector.}

\item{models}{A list of model names to be used for training.}

\item{bagging}{Logical flag indicating whether bagging should be applied (FALSE by default).}

\item{bagging_R}{The number of bootstrap replicates to use for bagging.}

\item{ensemble}{Logical flag indicating whether ensemble learning should be applied (FALSE by default).}

\item{feature_selection_method}{The method to be used for feature selection (if any).}

\item{k}{The number of top features to select.}

\item{drop_missing_records}{Logical flag indicating whether to drop records with missing values (TRUE by default).}

\item{fill_missing_method}{The method to be used for imputing missing values ('mean' by default).}

\item{scale_data}{Logical flag indicating whether to scale continuous variables (TRUE by default).}

\item{remove_outliers}{Logical flag indicating whether to remove outliers (FALSE by default).}

\item{seed}{An integer value to set the random seed for reproducibility (123 by default).}

\item{parameter_tuning}{Logical flag indicating whether to perform hyperparameter tuning (FALSE by default).}

\item{cv_folds}{The number of folds to use for cross-validation during parameter tuning (5 by default).}

\item{model_tuning_params}{A list of parameters for tuning the models (list() by default).}

\item{classification_threshold}{The threshold for converting probabilities to binary class labels
in classification tasks (0.5 by default).}

\item{ensemble_combine_method}{The method to combine models in ensemble learning ('stacking' by default).}
}
\value{
A list of items - The exact contents of the list depend on the chosen modeling strategy.
\enumerate{
\item containing model(s), predictions, and metrics if both ensemble and bagging are FALSE
\item predictions, variable importance scores, and metrics for bagging = TRUE && ensemble = FALSE,
\item predictions, and metrics for ensemble = TRUE && bagging = FALSE
}
}
\description{
This function provides a comprehensive approach to machine learning model development,
including preprocessing, model fitting, and ensemble learning. It supports various models,
preprocessing techniques such as feature selection, missing data imputation, scaling,
and outlier removal, as well as advanced model fitting strategies like bagging and ensembling.
Parameter tuning and model evaluation metrics are also integrated into the function.
}
\examples{
n <- 1000
p <- 10
X <- data.frame(matrix(rnorm(n * p), n, p))
y <- sample(0:1, n, replace = TRUE)
train_idx <- sample(1:n, 0.7 * n)
X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_test <- X[-train_idx, ]
y_test <- y[-train_idx]
models = list("random_forest")
model_tuning_params <- list("random_forest" = list(ntree=10))
results <- unifiedModelingToolkit(X = X_train, y = y_train, models = models, 
 model_tuning_params = model_tuning_params, bagging = FALSE, bagging_R = 100, 
 ensemble = FALSE, feature_selection_method = NULL, k = NULL, 
 drop_missing_records = FALSE, fill_missing_method = "mean", scale_data = FALSE, 
 remove_outliers = FALSE, seed = 123, parameter_tuning = FALSE, cv_folds = 10, 
 ensemble_combine_method = NULL)
make_predictions(results$model, X_test)
}
